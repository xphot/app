{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dash dash-cytoscape dash-bootstrap-components pyvis networkx numpy pandas scipy scikit-learn statsmodels plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwKlh0ZEcP75",
        "outputId": "913b2e8a-227c-42e8-cfa8-392969d3a475"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dash-cytoscape\n",
            "  Downloading dash_cytoscape-1.0.2.tar.gz (4.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dash-bootstrap-components\n",
            "  Downloading dash_bootstrap_components-1.7.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting Flask<3.1,>=1.0.4 (from dash)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting dash-html-components==2.0.0 (from dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash) (8.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash) (2.32.3)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.1.5)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2025.1.31)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading dash_bootstrap_components-1.7.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: dash-cytoscape\n",
            "  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-cytoscape: filename=dash_cytoscape-1.0.2-py3-none-any.whl size=4010716 sha256=c672c0fa6f019a890fdbe937ec6c57f999bad11a5f6b70f478c94cbe156edab1\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/b1/ab/6c999ab288b4849d372e23c0a8f6ece7edb7ffeb8c97959ab0\n",
            "Successfully built dash-cytoscape\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, jedi, Flask, pyvis, dash, dash-cytoscape, dash-bootstrap-components\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "Successfully installed Flask-3.0.3 Werkzeug-3.0.6 dash-2.18.2 dash-bootstrap-components-1.7.1 dash-core-components-2.0.0 dash-cytoscape-1.0.2 dash-html-components-2.0.0 dash-table-5.0.0 jedi-0.19.2 pyvis-0.3.2 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pMXlxZWundxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ae14ba-6eaf-4ff4-bd39-a2cdab267b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Descriptive Statistics:\n",
            "        ParticipantID        Age  LLMUsage  HerbalBlend  InitialSelfEfficacy  \\\n",
            "count      40.000000  40.000000  40.00000     40.00000            40.000000   \n",
            "mean       20.500000  24.500000   0.50000      0.50000             3.566601   \n",
            "std        11.690452   3.537347   0.50637      0.50637             0.512703   \n",
            "min         1.000000  18.000000   0.00000      0.00000             2.172412   \n",
            "25%        10.750000  22.000000   0.00000      0.00000             3.299213   \n",
            "50%        20.500000  25.000000   0.50000      0.50000             3.548638   \n",
            "75%        30.250000  28.000000   1.00000      1.00000             3.902698   \n",
            "max        40.000000  29.000000   1.00000      1.00000             5.186148   \n",
            "\n",
            "       FinalSelfEfficacy  InitialAnxiety  FinalAnxiety  ErrorsIdentified  \\\n",
            "count          40.000000       40.000000     40.000000         40.000000   \n",
            "mean            3.799448        2.460086      2.112920         13.075000   \n",
            "std             0.534244        0.534624      0.576600          4.091188   \n",
            "min             2.172412        1.286611      1.000000          5.000000   \n",
            "25%             3.467700        2.087068      1.783221         10.000000   \n",
            "50%             3.820082        2.444616      1.927741         13.000000   \n",
            "75%             4.150525        2.812352      2.550574         16.000000   \n",
            "max             5.000000        3.523963      3.342375         20.000000   \n",
            "\n",
            "       CompletionTime   EEGAlpha    EEGBeta     ECG_HR    EDA_SCR  \\\n",
            "count       40.000000  40.000000  40.000000  40.000000  40.000000   \n",
            "mean       298.210379   9.492228  19.599170  72.191092   0.419622   \n",
            "std         56.588924   2.142887   3.547296  12.043015   0.241358   \n",
            "min        168.976580   6.239375  12.028201  47.832389  -0.172819   \n",
            "25%        258.965296   7.885547  17.164040  60.808278   0.277953   \n",
            "50%        302.176013   9.307561  19.560060  74.349585   0.431821   \n",
            "75%        340.601678  10.740949  21.272803  81.027414   0.559456   \n",
            "max        398.780642  14.237772  29.561100  91.880170   0.928641   \n",
            "\n",
            "       POGFixations  POGFixationDuration  POGPupilDiameter  POGBlinkRate  \n",
            "count     40.000000            40.000000         40.000000     40.000000  \n",
            "mean      55.475000           356.659325          3.564476     19.682439  \n",
            "std       22.953674            96.763398          0.479751      5.028287  \n",
            "min       15.000000           209.694785          2.195606     10.636094  \n",
            "25%       37.250000           281.841938          3.206848     16.773946  \n",
            "50%       55.500000           347.404522          3.605449     19.928024  \n",
            "75%       75.000000           421.761703          3.913080     23.799278  \n",
            "max       99.000000           545.585815          4.359300     29.462207  \n",
            "\n",
            "Correlation Matrix:\n",
            "                    FinalSelfEfficacy  FinalAnxiety  ErrorsIdentified  \\\n",
            "FinalSelfEfficacy           1.000000     -0.307556          0.074183   \n",
            "FinalAnxiety               -0.307556      1.000000         -0.092609   \n",
            "ErrorsIdentified            0.074183     -0.092609          1.000000   \n",
            "CompletionTime              0.005821      0.046915          0.172697   \n",
            "\n",
            "                   CompletionTime  \n",
            "FinalSelfEfficacy        0.005821  \n",
            "FinalAnxiety             0.046915  \n",
            "ErrorsIdentified         0.172697  \n",
            "CompletionTime           1.000000  \n",
            "\n",
            "Group Comparison Results (T-tests):\n",
            " {'FinalSelfEfficacy': {'t-statistic': 3.4415259789827872, 'p-value': 0.0014210761722875916}, 'FinalAnxiety': {'t-statistic': -2.1833802350426983, 'p-value': 0.035252986938677254}, 'ErrorsIdentified': {'t-statistic': 1.2860111330473767, 'p-value': 0.20622034819887455}, 'CompletionTime': {'t-statistic': -0.24675104455094976, 'p-value': 0.8064290930184095}}\n",
            "\n",
            "Regression Results:\n",
            "                             OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:       ErrorsIdentified   R-squared:                       0.134\n",
            "Model:                            OLS   Adj. R-squared:                  0.006\n",
            "Method:                 Least Squares   F-statistic:                     1.045\n",
            "Date:                Mon, 17 Feb 2025   Prob (F-statistic):              0.403\n",
            "Time:                        05:40:44   Log-Likelihood:                -87.005\n",
            "No. Observations:                  32   AIC:                             184.0\n",
            "Df Residuals:                      27   BIC:                             191.3\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=======================================================================================\n",
            "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------\n",
            "Intercept              12.8433      0.712     18.048      0.000      11.383      14.303\n",
            "LLMUsage                1.2599      0.713      1.768      0.088      -0.202       2.722\n",
            "HerbalBlend             0.5248      0.715      0.734      0.469      -0.943       1.992\n",
            "InitialSelfEfficacy    -0.0597      0.821     -0.073      0.943      -1.744       1.625\n",
            "InitialAnxiety         -0.6530      0.692     -0.944      0.353      -2.072       0.766\n",
            "==============================================================================\n",
            "Omnibus:                        2.253   Durbin-Watson:                   2.160\n",
            "Prob(Omnibus):                  0.324   Jarque-Bera (JB):                1.231\n",
            "Skew:                           0.059   Prob(JB):                        0.540\n",
            "Kurtosis:                       2.046   Cond. No.                         1.40\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "SEM diagram saved to: /content/drive/MyDrive/data/sem_model_1.png\n",
            "SEM diagram saved to: /content/drive/MyDrive/data/sem_model_2.png\n",
            "SEM diagram saved to: /content/drive/MyDrive/data/sem_model_3.png\n",
            "Histogram saved to: /content/drive/MyDrive/data/histogram_self_efficacy.png\n",
            "Histogram saved to: /content/drive/MyDrive/data/histogram_anxiety.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4f05c824e337>:374: FutureWarning:\n",
            "\n",
            "\n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Violin plot saved to: /content/drive/MyDrive/data/violin_llm_self_efficacy.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4f05c824e337>:374: FutureWarning:\n",
            "\n",
            "\n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Violin plot saved to: /content/drive/MyDrive/data/violin_herbal_anxiety.png\n",
            "KDE plot saved to: /content/drive/MyDrive/data/kde_self_efficacy_errors.png\n",
            "KDE plot saved to: /content/drive/MyDrive/data/kde_anxiety_time.png\n",
            "Stacked bar plot saved to: /content/drive/MyDrive/data/stacked_bar_experience_errors.png\n",
            "Stacked bar plot saved to: /content/drive/MyDrive/data/stacked_bar_gender_time.png\n",
            "All plots saved to: /content/drive/MyDrive/data\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"HoT-SEM_Integrated_Analysis_Refactored_V3_Static_Visualizations_Final.ipynb\n",
        "\n",
        "This version addresses the `SyntaxError: invalid syntax` and further refines\n",
        "the code for Google Colab compatibility and robustness.  The key changes are:\n",
        "\n",
        "- **Corrected Syntax Error:** The syntax error was likely due to a copy-paste\n",
        "  issue or a stray character in the previous version.  This version ensures\n",
        "  the `import` statements are correct.\n",
        "- **Simplified Imports:**  Combines some imports for conciseness.\n",
        "- **Explicit Matplotlib Backend:**  Adds `plt.switch_backend('Agg')` to\n",
        "  explicitly set the Matplotlib backend to 'Agg'. This is often necessary\n",
        "  in Google Colab to prevent issues with displaying plots when not using\n",
        "  the interactive environment.\n",
        "- **Removed Redundant Theme Application:**  The neon theme is now applied\n",
        "  only once at the beginning of the main execution block, rather than\n",
        "  repeatedly within each plotting function.  This is more efficient.\n",
        "- **Checked for Empty Data:** Added a check to ensure the DataFrame `data`\n",
        "  is not empty before proceeding with analyses and plotting. This prevents\n",
        "  errors if, for some reason, the simulation fails to generate data.\n",
        "- **Further Improved Comments:** Added even more comments to clarify specific\n",
        "  lines and steps.\n",
        "\"\"\"\n",
        "\n",
        "# --- Imports ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf  # Corrected import\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from patsy import dmatrices\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Install Kaleido (for Plotly image export, if needed in the future) ---\n",
        "!pip install -U kaleido\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Define Output Directory ---\n",
        "output_dir = '/content/drive/MyDrive/data'  # Path to the 'data' folder\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "\n",
        "# --- Explicitly set Matplotlib backend to 'Agg' for Colab ---\n",
        "plt.switch_backend('Agg')\n",
        "\n",
        "# --- Neon Theme Function (for Matplotlib/Seaborn) ---\n",
        "def apply_neon_theme_mpl():\n",
        "    \"\"\"Applies a dark graphite background and neon colors to Matplotlib plots.\"\"\"\n",
        "    plt.style.use('dark_background')  # Set dark background\n",
        "    plt.rcParams['axes.facecolor'] = '#262626'  # Dark graphite\n",
        "    plt.rcParams['figure.facecolor'] = '#262626'\n",
        "    plt.rcParams['text.color'] = '#00FF00'  # Bright green text\n",
        "    plt.rcParams['axes.labelcolor'] = '#00FFFF'  # Cyan axis labels\n",
        "    plt.rcParams['xtick.color'] = '#00FFFF'\n",
        "    plt.rcParams['ytick.color'] = '#00FFFF'\n",
        "    plt.rcParams['grid.color'] = '#444444'  # Darker grid lines\n",
        "    # For Seaborn, set the style and palette\n",
        "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \"#262626\", \"grid.color\": \"#444444\"})\n",
        "    sns.set_palette(\"bright\")  # Use a bright, neon-like palette\n",
        "\n",
        "\n",
        "# --- Data Simulation (same as V2) ---\n",
        "def simulate_data(n_participants=40, seed=42):\n",
        "    \"\"\"Simulates data, including demographics, interventions, psychological\n",
        "    measures, performance, and neurophysiological data.  Effects of LLM and\n",
        "    herbal blend are simulated.\n",
        "\n",
        "    Args:\n",
        "        n_participants (int): Number of participants.\n",
        "        seed (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The simulated dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Demographics\n",
        "    age = np.random.randint(18, 30, size=n_participants)\n",
        "    gender = np.random.choice(['Male', 'Female', 'Other'], size=n_participants)\n",
        "    programming_experience = np.random.choice(\n",
        "        ['Beginner', 'Intermediate', 'Advanced'], size=n_participants\n",
        "    )\n",
        "\n",
        "    # Group Assignment (balanced)\n",
        "    llm_usage = np.array([1, 1, 0, 0] * (n_participants // 4))\n",
        "    herbal_blend = np.array([1, 0, 1, 0] * (n_participants // 4))\n",
        "\n",
        "    # Psychological Measures (initial and final)\n",
        "    initial_self_efficacy = np.random.normal(3.5, 0.5, size=n_participants)\n",
        "    initial_anxiety = np.random.normal(2.5, 0.6, size=n_participants)\n",
        "    final_self_efficacy = initial_self_efficacy.copy()\n",
        "    final_anxiety = initial_anxiety.copy()\n",
        "\n",
        "    # Performance Measures\n",
        "    errors_identified = np.random.randint(5, 20, size=n_participants)\n",
        "    completion_time = np.random.uniform(180, 400, size=n_participants)\n",
        "\n",
        "    # Adjust based on group (simulated effects)\n",
        "    for i in range(n_participants):\n",
        "        if llm_usage[i] == 1:\n",
        "            final_self_efficacy[i] += 0.5\n",
        "            final_anxiety[i] -= 0.4\n",
        "            errors_identified[i] += 3\n",
        "            completion_time[i] -= 15\n",
        "        if herbal_blend[i] == 1:\n",
        "            final_anxiety[i] -= 0.3\n",
        "            errors_identified[i] += 1\n",
        "\n",
        "    # Ensure reasonable bounds\n",
        "    final_self_efficacy = np.clip(final_self_efficacy, 1, 5)\n",
        "    final_anxiety = np.clip(final_anxiety, 1, 4)\n",
        "    errors_identified = np.maximum(0, errors_identified)\n",
        "    completion_time = np.maximum(60, completion_time)\n",
        "\n",
        "    # Neurophysiological Data (simplified)\n",
        "    eeg_alpha = np.random.normal(10, 2, size=n_participants)\n",
        "    eeg_beta = np.random.normal(18, 3, size=n_participants)\n",
        "    ecg_hr = np.random.normal(75, 10, size=n_participants)\n",
        "    eda_scr = np.random.normal(0.5, 0.2, size=n_participants)\n",
        "    pog_fixations = np.random.randint(20, 100, size=n_participants)\n",
        "    pog_fixation_duration = np.random.uniform(200, 500, size=n_participants)\n",
        "    pog_pupil_diameter = np.random.normal(3.5, 0.5, size=n_participants)\n",
        "    pog_blink_rate = np.random.uniform(10, 30, size=n_participants)\n",
        "\n",
        "    # Adjust based on group (simulated effects)\n",
        "    for i in range(n_participants):\n",
        "        if llm_usage[i] == 1:\n",
        "            eeg_beta[i] += 2\n",
        "            pog_fixations[i] -= 5\n",
        "            pog_fixation_duration[i] += 50\n",
        "        if herbal_blend[i] == 1:\n",
        "            ecg_hr[i] -= 5\n",
        "            eda_scr[i] -= 0.1\n",
        "\n",
        "    # Create DataFrame\n",
        "    data = pd.DataFrame({\n",
        "        'ParticipantID': range(1, n_participants + 1),\n",
        "        'Age': age,\n",
        "        'Gender': gender,\n",
        "        'ProgrammingExperience': programming_experience,\n",
        "        'LLMUsage': llm_usage,\n",
        "        'HerbalBlend': herbal_blend,\n",
        "        'InitialSelfEfficacy': initial_self_efficacy,\n",
        "        'FinalSelfEfficacy': final_self_efficacy,\n",
        "        'InitialAnxiety': initial_anxiety,\n",
        "        'FinalAnxiety': final_anxiety,\n",
        "        'ErrorsIdentified': errors_identified,\n",
        "        'CompletionTime': completion_time,\n",
        "        'EEGAlpha': eeg_alpha,\n",
        "        'EEGBeta': eeg_beta,\n",
        "        'ECG_HR': ecg_hr,\n",
        "        'EDA_SCR': eda_scr,\n",
        "        'POGFixations': pog_fixations,\n",
        "        'POGFixationDuration': pog_fixation_duration,\n",
        "        'POGPupilDiameter': pog_pupil_diameter,\n",
        "        'POGBlinkRate': pog_blink_rate\n",
        "    })\n",
        "\n",
        "    return data\n",
        "\n",
        "# --- Data Preprocessing (same as V2) ---\n",
        "\n",
        "def preprocess_data(data):\n",
        "    \"\"\"Preprocesses data: one-hot encodes categoricals, scales numericals,\n",
        "    and splits into training and testing sets.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The raw data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, X_test, y_train, y_test) preprocessed data splits.\n",
        "    \"\"\"\n",
        "\n",
        "    features = data.drop(columns=['ParticipantID', 'ErrorsIdentified', 'CompletionTime'])\n",
        "    performance = data[['ErrorsIdentified', 'CompletionTime']]\n",
        "    features = pd.get_dummies(features, columns=['Gender', 'ProgrammingExperience'])\n",
        "    numerical_features = features.select_dtypes(include=np.number).columns\n",
        "    scaler = StandardScaler()\n",
        "    features[numerical_features] = scaler.fit_transform(features[numerical_features])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, performance, test_size=0.2, random_state=42\n",
        "    )\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# --- Statistical Analyses (same as V2) ---\n",
        "\n",
        "def perform_statistical_analysis(data):\n",
        "    \"\"\"Performs descriptive stats, correlations, and group comparisons (t-tests).\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (descriptive_stats, correlation_matrix, group_comparison_results)\n",
        "    \"\"\"\n",
        "\n",
        "    descriptive_stats = data.describe()\n",
        "    correlation_matrix = data[[\n",
        "        'FinalSelfEfficacy', 'FinalAnxiety', 'ErrorsIdentified', 'CompletionTime'\n",
        "    ]].corr()\n",
        "    group_comparison_results = {}\n",
        "    for variable in ['FinalSelfEfficacy', 'FinalAnxiety', 'ErrorsIdentified', 'CompletionTime']:\n",
        "        llm_group = data[data['LLMUsage'] == 1][variable]\n",
        "        no_llm_group = data[data['LLMUsage'] == 0][variable]\n",
        "        t_stat, p_val = stats.ttest_ind(llm_group, no_llm_group)\n",
        "        group_comparison_results[variable] = {'t-statistic': t_stat, 'p-value': p_val}\n",
        "    return descriptive_stats, correlation_matrix, group_comparison_results\n",
        "\n",
        "\n",
        "def perform_regression_analysis(X_train, y_train, dependent_variable='ErrorsIdentified'):\n",
        "    \"\"\"Performs regression analysis using statsmodels.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features.\n",
        "        y_train (pd.DataFrame): Training target.\n",
        "        dependent_variable (str): Dependent variable to predict.\n",
        "\n",
        "    Returns:\n",
        "        statsmodels.regression.linear_model.RegressionResultsWrapper: Results.\n",
        "    \"\"\"\n",
        "\n",
        "    formula = f\"{dependent_variable} ~ LLMUsage + HerbalBlend + InitialSelfEfficacy + InitialAnxiety\"\n",
        "    y, X = dmatrices(formula, data=pd.concat([X_train, y_train], axis=1), return_type='dataframe')\n",
        "    X = sm.add_constant(X)\n",
        "    model = sm.OLS(y, X)\n",
        "    results = model.fit()\n",
        "    return results\n",
        "\n",
        "# --- Qualitative Analysis (same as V2, with zero-division handling) ---\n",
        "\n",
        "def analyze_prompts(data):\n",
        "    \"\"\"Simulates prompt analysis, generating more realistic prompt data\n",
        "    based on LLM usage and then analyzing it.  Handles potential\n",
        "    ZeroDivisionError.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The dataset.\n",
        "\n",
        "    Returns:\n",
        "        dict: Analysis results, including generated prompts.\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    for i in range(len(data)):\n",
        "        if data['LLMUsage'][i] == 1:\n",
        "            # Simulate more specific prompts for LLM users\n",
        "            prompt_type = random.choice([\"debug\", \"explain\", \"optimize\"])\n",
        "            if prompt_type == \"debug\":\n",
        "                prompts.append(f\"P{i+1}: Find the error in this code: `x = 10; y = 0; z = x / y`\")\n",
        "            elif prompt_type == \"explain\":\n",
        "                prompts.append(f\"P{i+1}: Explain what this function does: `def add(a, b): return a + b`\")\n",
        "            else:  # optimize\n",
        "                prompts.append(f\"P{i+1}: How can I make this code faster: `for i in range(1000000): pass`\")\n",
        "        else:\n",
        "            # Simulate more general questions for non-LLM users\n",
        "            prompts.append(f\"P{i+1}: I'm stuck on this task, can you give me a hint?\")\n",
        "\n",
        "    # Analyze the generated prompts\n",
        "    prompt_lengths = [len(p.split()) for p in prompts]\n",
        "    # Handle potential ZeroDivisionError if prompt_lengths is empty\n",
        "    average_prompt_length = np.mean(prompt_lengths) if prompt_lengths else 0\n",
        "\n",
        "    # Count keywords (more robustly)\n",
        "    keyword_counts = defaultdict(int)\n",
        "    for p in prompts:\n",
        "        for word in p.lower().split():\n",
        "            if word not in [\"i\", \"this\", \"the\", \"a\", \"in\", \"on\", \"can\", \"you\", \"me\", \"what\", \"how\", \"is\", \"do\", \"does\", \"an\", \"here\", \"fix\"]: # Common words\n",
        "                keyword_counts[word] += 1\n",
        "    most_common_keywords = sorted(keyword_counts.items(), key=lambda item: item[1], reverse=True)[:5]\n",
        "\n",
        "\n",
        "    prompt_analysis = {\n",
        "        \"prompts\": prompts,  # Include the generated prompts\n",
        "        \"average_prompt_length\": average_prompt_length,\n",
        "        \"most_common_keywords\": most_common_keywords,\n",
        "        \"question_types\": [\"debug\", \"explain\", \"optimize\", \"general help\"],  # Based on simulation\n",
        "    }\n",
        "    return prompt_analysis\n",
        "\n",
        "\n",
        "def analyze_interviews(data):\n",
        "    \"\"\"Simulates interview analysis, generating more realistic feedback.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The dataset.\n",
        "\n",
        "    Returns:\n",
        "        dict: Analysis results, including generated feedback.\n",
        "    \"\"\"\n",
        "    qualitative_feedback = []\n",
        "    for i in range(len(data)):\n",
        "        if data['LLMUsage'][i] == 1:\n",
        "            feedback = random.choice([\n",
        "                \"The LLM helped me find the bug quickly.\",\n",
        "                \"I understood the code better with the LLM's explanation.\",\n",
        "                \"The LLM gave me suggestions I wouldn't have thought of.\"\n",
        "            ])\n",
        "        else:\n",
        "            feedback = random.choice([\n",
        "                \"I wish I had a tool to help me understand the code.\",\n",
        "                \"I spent a lot of time trying to find the error myself.\",\n",
        "                \"It was difficult to debug without assistance.\"\n",
        "            ])\n",
        "        qualitative_feedback.append(f\"P{i+1}: {feedback}\")\n",
        "\n",
        "    interview_analysis = {\n",
        "        \"perceived_usefulness_llm\": np.random.uniform(3, 5) if data['LLMUsage'].any() else np.random.uniform(1, 3),\n",
        "        \"anxiety_reduction_llm\": np.random.uniform(1, 3) if data['LLMUsage'].any() else np.random.uniform(0, 1),\n",
        "        \"anxiety_reduction_herbal\": np.random.uniform(1, 3) if data['HerbalBlend'].any() else np.random.uniform(0, 1),\n",
        "        \"qualitative_feedback\": qualitative_feedback,  # Include generated feedback\n",
        "    }\n",
        "    return interview_analysis\n",
        "\n",
        "# --- SEM Diagram Generation (using Matplotlib) ---\n",
        "\n",
        "def create_sem_diagram_mpl(model_name, nodes, edges, filename):\n",
        "    \"\"\"Creates a conceptual SEM diagram using Matplotlib and saves it as PNG.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model.\n",
        "        nodes (dict): Dictionary of node labels and positions: {'node_label': (x, y)}.\n",
        "        edges (list of tuples): List of edges: [(source, target), ...].\n",
        "        filename (str): Output filename.\n",
        "    \"\"\"\n",
        "    # No need to apply theme here, it's done globally\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Draw nodes\n",
        "    for label, pos in nodes.items():\n",
        "        ax.add_patch(plt.Circle(pos, 0.3, color='#00FFFF', zorder=2))  # Cyan circles\n",
        "        ax.text(pos[0], pos[1], label, color='black', ha='center', va='center', fontsize=10, zorder=3)\n",
        "\n",
        "    # Draw edges\n",
        "    for source, target in edges:\n",
        "        x1, y1 = nodes[source]\n",
        "        x2, y2 = nodes[target]\n",
        "        ax.arrow(x1, y1, x2 - x1, y2 - y1, head_width=0.1, head_length=0.2, fc='#00FF00', ec='#00FF00', length_includes_head=True, zorder=1)\n",
        "\n",
        "    ax.set_title(f\"SEM Model: {model_name}\", color='#00FFFF')\n",
        "    ax.axis('off')  # Hide axes\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close(fig)\n",
        "    print(f\"SEM diagram saved to: {filename}\")\n",
        "\n",
        "\n",
        "# --- Statistical Plotting Functions (Matplotlib/Seaborn) ---\n",
        "\n",
        "def create_histogram_mpl(data, column, filename):\n",
        "    \"\"\"Creates a histogram with the neon theme (Matplotlib).\"\"\"\n",
        "    # No need to apply theme here\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(data[column], kde=False, color='#00FFFF')  # Cyan bars\n",
        "    plt.title(f\"Histogram of {column}\")\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\"Histogram saved to: {filename}\")\n",
        "\n",
        "def create_violin_plot_mpl(data, x_column, y_column, filename):\n",
        "    \"\"\"Creates a violin plot with the neon theme (Matplotlib/Seaborn).\"\"\"\n",
        "    # No need to apply theme here\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.violinplot(x=data[x_column], y=data[y_column], palette=\"bright\")\n",
        "    plt.title(f\"Violin Plot of {y_column} by {x_column}\")\n",
        "    plt.xlabel(x_column)\n",
        "    plt.ylabel(y_column)\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\"Violin plot saved to: {filename}\")\n",
        "\n",
        "def create_kde_plot_mpl(data, column1, column2, filename):\n",
        "    \"\"\"Creates a 2D KDE plot with the neon theme (Matplotlib/Seaborn).\"\"\"\n",
        "    # No need to apply theme here\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.kdeplot(x=data[column1], y=data[column2], cmap=\"coolwarm\", fill=True, thresh=0, levels=100, cbar=True)\n",
        "    plt.title(f\"KDE Plot of {column1} vs. {column2}\")\n",
        "    plt.xlabel(column1)\n",
        "    plt.ylabel(column2)\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\"KDE plot saved to: {filename}\")\n",
        "\n",
        "def create_stacked_bar_plot_mpl(data, x_column, y_column, color_column, filename):\n",
        "    \"\"\"Creates a stacked bar plot (Matplotlib/Seaborn).\"\"\"\n",
        "    # No need to apply theme here\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    # Create a pivot table for the stacked bar plot\n",
        "    pivot_data = data.groupby([x_column, color_column])[y_column].mean().unstack()\n",
        "    pivot_data.plot(kind='bar', stacked=True, ax=plt.gca(), colormap='cool') # Use cool colormap\n",
        "    plt.title(f\"Stacked Bar Plot of {y_column} by {x_column} and {color_column}\")\n",
        "    plt.xlabel(x_column)\n",
        "    plt.ylabel(y_column)\n",
        "    plt.legend(title=color_column)\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\"Stacked bar plot saved to: {filename}\")\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Simulate data\n",
        "    data = simulate_data()\n",
        "\n",
        "    # Check if data is empty\n",
        "    if data.empty:\n",
        "        print(\"Error: Simulated data is empty.  Check the simulation function.\")\n",
        "        exit()\n",
        "\n",
        "    # Preprocess data\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
        "\n",
        "    # Perform statistical analyses\n",
        "    statistical_results = perform_statistical_analysis(data)\n",
        "    descriptive_stats, correlation_matrix, group_comparison_results = statistical_results\n",
        "    print(\"Descriptive Statistics:\\n\", descriptive_stats)\n",
        "    print(\"\\nCorrelation Matrix:\\n\", correlation_matrix)\n",
        "    print(\"\\nGroup Comparison Results (T-tests):\\n\", group_comparison_results)\n",
        "\n",
        "    # Perform regression analysis\n",
        "    regression_results = perform_regression_analysis(X_train, y_train)\n",
        "    print(\"\\nRegression Results:\\n\", regression_results.summary())\n",
        "\n",
        "    # Perform qualitative analyses\n",
        "    prompt_analysis = analyze_prompts(data)\n",
        "    interview_analysis = analyze_interviews(data)\n",
        "    qualitative_results = (prompt_analysis, interview_analysis)\n",
        "\n",
        "    # --- Apply Neon Theme Globally ---\n",
        "    apply_neon_theme_mpl()\n",
        "\n",
        "    # --- Create SEM Diagrams ---\n",
        "    # Model 1: Basic Model\n",
        "    nodes1 = {\n",
        "        'LLM': (1, 3), 'Herbal': (1, 1), 'SelfEfficacy': (3, 3),\n",
        "        'Anxiety': (3, 1), 'Performance': (5, 2)\n",
        "    }\n",
        "    edges1 = [('LLM', 'SelfEfficacy'), ('LLM', 'Anxiety'), ('LLM', 'Performance'),\n",
        "              ('Herbal', 'Anxiety'), ('SelfEfficacy', 'Performance'), ('Anxiety', 'Performance')]\n",
        "    create_sem_diagram_mpl(\"Model 1\", nodes1, edges1, os.path.join(output_dir, \"sem_model_1.png\"))\n",
        "\n",
        "    # Model 2:  With Mediators\n",
        "    nodes2 = {\n",
        "        'LLM': (1, 4), 'Herbal': (1, 1), 'SelfEfficacy': (3, 4),\n",
        "        'Anxiety': (3, 1), 'Performance': (5, 2.5), 'EEG': (2, 5), 'EDA': (2, 0)\n",
        "    }\n",
        "    edges2 = [('LLM', 'SelfEfficacy'), ('LLM', 'Anxiety'), ('LLM', 'Performance'),\n",
        "              ('Herbal', 'Anxiety'), ('SelfEfficacy', 'Performance'), ('Anxiety', 'Performance'),\n",
        "              ('LLM', 'EEG'), ('Herbal', 'EDA'), ('EEG', 'Anxiety'), ('EDA', 'Anxiety')]\n",
        "    create_sem_diagram_mpl(\"Model 2\", nodes2, edges2, os.path.join(output_dir, \"sem_model_2.png\"))\n",
        "\n",
        "    # Model 3: Full Model (Hypothetical)\n",
        "    nodes3 = {\n",
        "        'LLM': (1, 5), 'Herbal': (1, 1), 'SelfEfficacy': (3, 5), 'Anxiety': (3, 1),\n",
        "        'Performance': (5, 3), 'EEG': (2, 6), 'EDA': (2, 0), 'POG': (6, 3),\n",
        "        'InitialSE': (4, 6), 'FinalSE': (4, 4), 'InitialAnx': (4, 0), 'FinalAnx': (4, 2)\n",
        "    }\n",
        "    edges3 = [('LLM', 'SelfEfficacy'), ('LLM', 'Anxiety'), ('LLM', 'Performance'),\n",
        "              ('Herbal', 'Anxiety'), ('SelfEfficacy', 'Performance'), ('Anxiety', 'Performance'),\n",
        "              ('LLM', 'EEG'), ('Herbal', 'EDA'), ('EEG', 'Anxiety'), ('EDA', 'Anxiety'), ('POG', 'Performance'),\n",
        "              ('InitialSE', 'FinalSE'), ('InitialAnx', 'FinalAnx')]\n",
        "    create_sem_diagram_mpl(\"Model 3\", nodes3, edges3, os.path.join(output_dir, \"sem_model_3.png\"))\n",
        "\n",
        "    # --- Create Statistical Plots ---\n",
        "    # 2 Histograms\n",
        "    create_histogram_mpl(data, 'FinalSelfEfficacy', os.path.join(output_dir, 'histogram_self_efficacy.png'))\n",
        "    create_histogram_mpl(data, 'FinalAnxiety', os.path.join(output_dir, 'histogram_anxiety.png'))\n",
        "\n",
        "    # 2 Violin Plots\n",
        "    create_violin_plot_mpl(data, 'LLMUsage', 'FinalSelfEfficacy', os.path.join(output_dir, 'violin_llm_self_efficacy.png'))\n",
        "    create_violin_plot_mpl(data, 'HerbalBlend', 'FinalAnxiety', os.path.join(output_dir, 'violin_herbal_anxiety.png'))\n",
        "\n",
        "    # 2 KDE Plots\n",
        "    create_kde_plot_mpl(data, 'FinalSelfEfficacy', 'ErrorsIdentified', os.path.join(output_dir, 'kde_self_efficacy_errors.png'))\n",
        "    create_kde_plot_mpl(data, 'FinalAnxiety', 'CompletionTime', os.path.join(output_dir, 'kde_anxiety_time.png'))\n",
        "\n",
        "    # 2 Stacked Bar Plots\n",
        "    create_stacked_bar_plot_mpl(data, 'ProgrammingExperience', 'ErrorsIdentified', 'LLMUsage', os.path.join(output_dir, 'stacked_bar_experience_errors.png'))\n",
        "    create_stacked_bar_plot_mpl(data, 'Gender', 'CompletionTime', 'HerbalBlend', os.path.join(output_dir, 'stacked_bar_gender_time.png'))\n",
        "\n",
        "    print(f\"All plots saved to: {output_dir}\")"
      ]
    }
  ]
}